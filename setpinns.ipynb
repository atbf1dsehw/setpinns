{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all the imports\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import LBFGS, AdamW\n",
    "from tqdm import tqdm\n",
    "from src.util import *\n",
    "from src.model.setpinns import SetPinns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.set_warn_always(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xavier init and functions to get the analytical sol\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "def h(x):\n",
    "    return np.exp(-((x - np.pi) ** 2) / (2 * (np.pi / 4) ** 2))\n",
    "\n",
    "\n",
    "def u_ana(x, t):\n",
    "    return h(x) * np.exp(5 * t) / (h(x) * np.exp(5 * t) + 1 - h(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "res_points = 50\n",
    "test_points = 101\n",
    "val_points = 21\n",
    "set_dim=2\n",
    "device = \"cuda:0\"\n",
    "\n",
    "res, b_left, b_right, b_upper, b_lower = get_data(\n",
    "    [0, 2 * np.pi], [0, 1], res_points, res_points\n",
    ")\n",
    "res_test, _, _, _, _ = get_data([0, 2 * np.pi], [0, 1], test_points, test_points)\n",
    "# val\n",
    "res_val, _, _, _, _ = get_data([0, 2 * np.pi], [0, 1], val_points, val_points)\n",
    "u = torch.from_numpy(u_ana(res_val[:, 0], res_val[:, 1])).reshape(-1).to(device)\n",
    "res_val = torch.tensor(res_val, dtype=torch.float32, requires_grad=True).to(device)\n",
    "x_val, t_val = res_val[:, 0:1], res_val[:, 1:2]\n",
    "x_val, t_val = x_val.reshape(-1, 1, 1), t_val.reshape(-1, 1, 1)\n",
    "\n",
    "\n",
    "res = res.reshape(res_points, res_points, 2)\n",
    "res = (\n",
    "    res.reshape(\n",
    "        res.shape[0] // set_dim, set_dim, res.shape[1] // set_dim, set_dim, 2\n",
    "    )\n",
    "    .swapaxes(1, 2)\n",
    "    .reshape(-1, set_dim, set_dim, 2)\n",
    ")\n",
    "res = res.reshape(res.shape[0], -1, 2)\n",
    "\n",
    "res = torch.tensor(res, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_left = torch.tensor(b_left, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_right = torch.tensor(b_right, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_upper = torch.tensor(b_upper, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_lower = torch.tensor(b_lower, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "x_res, t_res = res[:, :, 0], res[:, :, 1]\n",
    "x_left, t_left = b_left[:, 0], b_left[:, 1]\n",
    "x_right, t_right = b_right[:, 0], b_right[:, 1]\n",
    "x_upper, t_upper = b_upper[:, 0], b_upper[:, 1]\n",
    "x_lower, t_lower = b_lower[:, 0], b_lower[:, 1]\n",
    "(\n",
    "    x_res,\n",
    "    t_res,\n",
    "    x_left,\n",
    "    t_left,\n",
    "    x_right,\n",
    "    t_right,\n",
    "    x_upper,\n",
    "    t_upper,\n",
    "    x_lower,\n",
    "    t_lower,\n",
    ") = (\n",
    "    x_res.unsqueeze(-1),\n",
    "    t_res.unsqueeze(-1),\n",
    "    make_set_sequence(x_left, set_dim),\n",
    "    make_set_sequence(t_left, set_dim),\n",
    "    make_set_sequence(x_right, set_dim),\n",
    "    make_set_sequence(t_right, set_dim),\n",
    "    make_set_sequence(x_upper, set_dim),\n",
    "    make_set_sequence(t_upper, set_dim),\n",
    "    make_set_sequence(x_lower, set_dim),\n",
    "    make_set_sequence(t_lower, set_dim),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on set size, now we have created sets of residual points as well as boundary and initial points. Note that the points in a set are close to each other. By changing the hyper-parameters, you can vary on how \"close\" these points can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000],\n",
       "         [0.1282]],\n",
       "\n",
       "        [[0.2565],\n",
       "         [0.3847]],\n",
       "\n",
       "        [[0.5129],\n",
       "         [0.6411]],\n",
       "\n",
       "        [[0.7694],\n",
       "         [0.8976]],\n",
       "\n",
       "        [[1.0258],\n",
       "         [1.1541]],\n",
       "\n",
       "        [[1.2823],\n",
       "         [1.4105]],\n",
       "\n",
       "        [[1.5387],\n",
       "         [1.6670]],\n",
       "\n",
       "        [[1.7952],\n",
       "         [1.9234]],\n",
       "\n",
       "        [[2.0517],\n",
       "         [2.1799]],\n",
       "\n",
       "        [[2.3081],\n",
       "         [2.4363]],\n",
       "\n",
       "        [[2.5646],\n",
       "         [2.6928]],\n",
       "\n",
       "        [[2.8210],\n",
       "         [2.9493]],\n",
       "\n",
       "        [[3.0775],\n",
       "         [3.2057]],\n",
       "\n",
       "        [[3.3339],\n",
       "         [3.4622]],\n",
       "\n",
       "        [[3.5904],\n",
       "         [3.7186]],\n",
       "\n",
       "        [[3.8468],\n",
       "         [3.9751]],\n",
       "\n",
       "        [[4.1033],\n",
       "         [4.2315]],\n",
       "\n",
       "        [[4.3598],\n",
       "         [4.4880]],\n",
       "\n",
       "        [[4.6162],\n",
       "         [4.7444]],\n",
       "\n",
       "        [[4.8727],\n",
       "         [5.0009]],\n",
       "\n",
       "        [[5.1291],\n",
       "         [5.2574]],\n",
       "\n",
       "        [[5.3856],\n",
       "         [5.5138]],\n",
       "\n",
       "        [[5.6420],\n",
       "         [5.7703]],\n",
       "\n",
       "        [[5.8985],\n",
       "         [6.0267]],\n",
       "\n",
       "        [[6.1550],\n",
       "         [6.2832]]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000],\n",
       "         [0.0204]],\n",
       "\n",
       "        [[0.0408],\n",
       "         [0.0612]],\n",
       "\n",
       "        [[0.0816],\n",
       "         [0.1020]],\n",
       "\n",
       "        [[0.1224],\n",
       "         [0.1429]],\n",
       "\n",
       "        [[0.1633],\n",
       "         [0.1837]],\n",
       "\n",
       "        [[0.2041],\n",
       "         [0.2245]],\n",
       "\n",
       "        [[0.2449],\n",
       "         [0.2653]],\n",
       "\n",
       "        [[0.2857],\n",
       "         [0.3061]],\n",
       "\n",
       "        [[0.3265],\n",
       "         [0.3469]],\n",
       "\n",
       "        [[0.3673],\n",
       "         [0.3878]],\n",
       "\n",
       "        [[0.4082],\n",
       "         [0.4286]],\n",
       "\n",
       "        [[0.4490],\n",
       "         [0.4694]],\n",
       "\n",
       "        [[0.4898],\n",
       "         [0.5102]],\n",
       "\n",
       "        [[0.5306],\n",
       "         [0.5510]],\n",
       "\n",
       "        [[0.5714],\n",
       "         [0.5918]],\n",
       "\n",
       "        [[0.6122],\n",
       "         [0.6327]],\n",
       "\n",
       "        [[0.6531],\n",
       "         [0.6735]],\n",
       "\n",
       "        [[0.6939],\n",
       "         [0.7143]],\n",
       "\n",
       "        [[0.7347],\n",
       "         [0.7551]],\n",
       "\n",
       "        [[0.7755],\n",
       "         [0.7959]],\n",
       "\n",
       "        [[0.8163],\n",
       "         [0.8367]],\n",
       "\n",
       "        [[0.8571],\n",
       "         [0.8776]],\n",
       "\n",
       "        [[0.8980],\n",
       "         [0.9184]],\n",
       "\n",
       "        [[0.9388],\n",
       "         [0.9592]],\n",
       "\n",
       "        [[0.9796],\n",
       "         [1.0000]]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000],\n",
       "         [0.1282],\n",
       "         [0.0000],\n",
       "         [0.1282]],\n",
       "\n",
       "        [[0.2565],\n",
       "         [0.3847],\n",
       "         [0.2565],\n",
       "         [0.3847]],\n",
       "\n",
       "        [[0.5129],\n",
       "         [0.6411],\n",
       "         [0.5129],\n",
       "         [0.6411]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[5.6420],\n",
       "         [5.7703],\n",
       "         [5.6420],\n",
       "         [5.7703]],\n",
       "\n",
       "        [[5.8985],\n",
       "         [6.0267],\n",
       "         [5.8985],\n",
       "         [6.0267]],\n",
       "\n",
       "        [[6.1550],\n",
       "         [6.2832],\n",
       "         [6.1550],\n",
       "         [6.2832]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now initialize the model and few important variables. One can use any variant of the Tranformer model.\n",
    "# define setpinns\n",
    "model = SetPinns(d_out=1, d_hidden=512, d_model=32, N=1, heads=2).to(device)\n",
    "# apply xavier init\n",
    "model.apply(init_weights)\n",
    "best_val = np.inf\n",
    "loss_track = []\n",
    "val_track = []\n",
    "best_model_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam Training\n",
      "Best val reached at 0\n",
      "Best val reached at 1\n",
      "Best val reached at 6\n",
      "Best val reached at 29\n",
      "Best val reached at 30\n",
      "Best val reached at 31\n",
      "Best val reached at 32\n",
      "Best val reached at 33\n",
      "Best val reached at 34\n",
      "Best val reached at 35\n",
      "Best val reached at 60\n",
      "Best val reached at 61\n",
      "Best val reached at 62\n",
      "Best val reached at 63\n",
      "Best val reached at 64\n",
      "Best val reached at 65\n",
      "Best val reached at 66\n"
     ]
    }
   ],
   "source": [
    "# now perform training with AdamW\n",
    "# adam training\n",
    "optim = AdamW(model.parameters(), lr=3e-4)\n",
    "print(f\"Adam Training\")\n",
    "for i in range(100):\n",
    "    model.train()\n",
    "    pred_res = model(x_res, t_res)\n",
    "    pred_left = model(x_left, t_left)\n",
    "    pred_upper = model(x_upper, t_upper)\n",
    "    pred_lower = model(x_lower, t_lower)\n",
    "    u_t = torch.autograd.grad(\n",
    "        pred_res,\n",
    "        t_res,\n",
    "        grad_outputs=torch.ones_like(pred_res),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0]\n",
    "    loss_res = torch.mean((u_t - 5 * pred_res * (1 - pred_res)) ** 2)\n",
    "    loss_bc = torch.mean((pred_upper - pred_lower) ** 2)\n",
    "    loss_ic = torch.mean(\n",
    "        (\n",
    "            pred_left[:, 0]\n",
    "            - torch.exp(\n",
    "                -((x_left[:, 0] - torch.pi) ** 2) / (2 * (torch.pi / 4) ** 2)\n",
    "            )\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "\n",
    "    loss_track.append([loss_res.item(), loss_bc.item(), loss_ic.item()])\n",
    "\n",
    "    loss = loss_res + loss_bc + loss_ic\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    pred = model(x_val, t_val)\n",
    "    pred = pred.reshape(-1)\n",
    "    r = F.mse_loss(pred, u).item()\n",
    "    val_track.append(r)\n",
    "    if r < best_val:\n",
    "        print(f\"Best val reached at {i}\")\n",
    "        best_val = r\n",
    "        best_model_weights = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val reached at 0\n",
      "Best val reached at 1\n",
      "Best val reached at 2\n",
      "Best val reached at 35\n",
      "Best val reached at 36\n",
      "Best val reached at 37\n",
      "Best val reached at 38\n",
      "Best val reached at 39\n",
      "Best val reached at 41\n",
      "Best val reached at 42\n",
      "Best val reached at 43\n",
      "Best val reached at 45\n",
      "Best val reached at 46\n",
      "Best val reached at 47\n",
      "Best val reached at 51\n",
      "Best val reached at 52\n",
      "Best val reached at 53\n",
      "Best val reached at 54\n",
      "Best val reached at 59\n",
      "Best val reached at 60\n",
      "Best val reached at 61\n",
      "Best val reached at 65\n",
      "Best val reached at 66\n"
     ]
    }
   ],
   "source": [
    "# now tune the model using LBFGS\n",
    "model.load_state_dict(best_model_weights)\n",
    "model.to(device)\n",
    "optim = LBFGS(model.parameters(), line_search_fn=\"strong_wolfe\")\n",
    "for i in range(1000):\n",
    "    model.train()\n",
    "\n",
    "    def closure():\n",
    "        pred_res = model(x_res, t_res)\n",
    "        pred_left = model(x_left, t_left)\n",
    "        pred_upper = model(x_upper, t_upper)\n",
    "        pred_lower = model(x_lower, t_lower)\n",
    "        u_t = torch.autograd.grad(\n",
    "            pred_res,\n",
    "            t_res,\n",
    "            grad_outputs=torch.ones_like(pred_res),\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "        loss_res = torch.mean((u_t - 5 * pred_res * (1 - pred_res)) ** 2)\n",
    "        loss_bc = torch.mean((pred_upper - pred_lower) ** 2)\n",
    "        loss_ic = torch.mean(\n",
    "            (\n",
    "                pred_left[:, 0]\n",
    "                - torch.exp(\n",
    "                    -((x_left[:, 0] - torch.pi) ** 2) / (2 * (torch.pi / 4) ** 2)\n",
    "                )\n",
    "            )\n",
    "            ** 2\n",
    "        )\n",
    "\n",
    "        loss_track.append([loss_res.item(), loss_bc.item(), loss_ic.item()])\n",
    "\n",
    "        loss = loss_res + loss_bc + loss_ic\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optim.step(closure)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    pred = model(x_val, t_val)\n",
    "    pred = pred.reshape(-1)\n",
    "    r = F.mse_loss(pred, u).item()\n",
    "    val_track.append(r)\n",
    "    if r < best_val:\n",
    "        print(f\"Best val reached at {i}\")\n",
    "        best_val = r\n",
    "        best_model_weights = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rRMSE: 0.042286\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model_weights)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "res_test = torch.tensor(res_test, dtype=torch.float32, requires_grad=True).to(\n",
    "        device\n",
    "    )\n",
    "x_test, t_test = res_test[:, 0:1], res_test[:, 1:2]\n",
    "x_test, t_test = x_test.reshape(-1, 1, 1), t_test.reshape(-1, 1, 1)\n",
    "with torch.no_grad():\n",
    "    pred = model(x_test, t_test)\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "pred = pred.reshape(test_points, test_points)\n",
    "res_test, _, _, _, _ = get_data([0, 2 * np.pi], [0, 1], test_points, test_points)\n",
    "u = u_ana(res_test[:, 0], res_test[:, 1]).reshape(test_points, test_points)\n",
    "\n",
    "rl1 = np.sum(np.abs(u - pred)) / np.sum(np.abs(u))\n",
    "rl2 = np.sqrt(np.sum((u - pred) ** 2) / np.sum(u**2))\n",
    "\n",
    "print(\"rRMSE: {:4f}\".format(rl2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "setpinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
